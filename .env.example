# aegis-llm-server environment template
# Copy to `.env` and adjust for your local/deployment profile.
#
# IMPORTANT:
# - aegis-llm-server reads process environment variables (prefix `AEGIS_LLM_SERVER_`).
# - It does NOT parse `.env` directly; load env externally before start.

# ------------------------------
# Service identity
# ------------------------------
AEGIS_LLM_SERVER_SERVICE_NAME=aegis-llm-server
AEGIS_LLM_SERVER_SERVICE_VERSION=0.1.0

# ------------------------------
# Server
# ------------------------------
AEGIS_LLM_SERVER_SERVER__HOST=0.0.0.0
AEGIS_LLM_SERVER_SERVER__PORT=8181
# Optional process-level override
# PORT=8181

# ------------------------------
# Embedding backend
# ------------------------------
AEGIS_LLM_SERVER_EMBEDDING__ENABLED=true
AEGIS_LLM_SERVER_EMBEDDING__BACKEND=deterministic
AEGIS_LLM_SERVER_EMBEDDING__MODEL_NAME=nomic-ai/nomic-embed-text-v1.5
AEGIS_LLM_SERVER_EMBEDDING__TRUST_REMOTE_CODE=true
AEGIS_LLM_SERVER_EMBEDDING__DIMENSION=768
AEGIS_LLM_SERVER_EMBEDDING__NORMALIZE=true
# Production recommendation:
# - use an in-process local model backend (no forwarding/proxy hop)
# - keep MODEL_NAME set to the local embedding model to load
# - current real local backend option: sentence_transformers (install `.[local]`)

# ------------------------------
# Hardening limits
# ------------------------------
AEGIS_LLM_SERVER_EMBEDDING__MAX_BATCH_SIZE=64
AEGIS_LLM_SERVER_EMBEDDING__MAX_INPUT_CHARS=32768
AEGIS_LLM_SERVER_EMBEDDING__MAX_TOTAL_CHARS=262144
AEGIS_LLM_SERVER_EMBEDDING__BACKEND_TIMEOUT_SECONDS=30

# ------------------------------
# Telemetry (optional)
# ------------------------------
AEGIS_LLM_SERVER_TELEMETRY__ENABLED=false
AEGIS_LLM_SERVER_TELEMETRY__OTLP_ENDPOINT=http://127.0.0.1:4318
AEGIS_LLM_SERVER_TELEMETRY__OTLP_TIMEOUT_SECONDS=10
AEGIS_LLM_SERVER_TELEMETRY__METRICS_EXPORT_INTERVAL_MS=5000
AEGIS_LLM_SERVER_TELEMETRY__SAMPLE_RATIO=1.0
# Optional OTLP headers map:
# AEGIS_LLM_SERVER_TELEMETRY__OTLP_HEADERS__Authorization=Bearer token
