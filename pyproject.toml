[project]
name = "aegis-llm-server"
version = "0.1.0"
description = "OpenAI-compatible local LLM server for embeddings and local inference workloads."
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
  "fastapi>=0.115.0,<1.0.0",
  "numpy>=1.26.0,<3.0.0",
  "opentelemetry-api>=1.24.0,<2.0.0",
  "opentelemetry-exporter-otlp-proto-http>=1.24.0,<2.0.0",
  "opentelemetry-instrumentation-fastapi>=0.45b0,<1.0.0",
  "opentelemetry-sdk>=1.24.0,<2.0.0",
  "pydantic>=2.8.0,<3.0.0",
  "pydantic-settings>=2.4.0,<3.0.0",
  "uvicorn[standard]>=0.30.0,<1.0.0",
]

[project.optional-dependencies]
local = [
  "einops>=0.8.0,<1.0.0",
  "sentence-transformers>=3.0.0,<4.0.0",
]
dev = [
  "httpx>=0.27.0,<1.0.0",
  "pytest>=8.0.0,<9.0.0",
  "pytest-asyncio>=0.24.0,<1.0.0",
  "ruff>=0.12.0,<1.0.0",
]

[project.scripts]
aegis-llm-server = "aegis_llm_server.main:run"

[tool.pytest.ini_options]
testpaths = ["tests"]

[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"
